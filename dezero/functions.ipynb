{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dezero.core import Function,Variable, as_array, as_variable\n",
    "from dezero.core import as_variable\n",
    "from dezero import utils\n",
    "from dezero import cuda\n",
    "import dezero\n",
    "from dezero.functions_conv import conv2d\n",
    "# from dezero.functions_conv import deconv2d\n",
    "from dezero.functions_conv import conv2d_simple\n",
    "from dezero.functions_conv import im2col\n",
    "# from dezero.functions_conv import col2im\n",
    "from dezero.functions_conv import pooling_simple\n",
    "from dezero.functions_conv import pooling\n",
    "# from dezero.functions_conv import average_pooling\n",
    "from dezero.core import add\n",
    "from dezero.core import sub\n",
    "from dezero.core import rsub\n",
    "from dezero.core import mul\n",
    "from dezero.core import div\n",
    "from dezero.core import neg\n",
    "from dezero.core import pow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sin(Function):\n",
    "    def forward(self, x):\n",
    "        xp = cuda.get_array_module(x)\n",
    "        y = xp.sin(x)\n",
    "        return y\n",
    "    \n",
    "    def backward(self, gy):\n",
    "        x, = self.inputs\n",
    "        gx = gy * cos(x)\n",
    "        return gx\n",
    "    \n",
    "def sin(x):\n",
    "    return Sin()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cos(Function):\n",
    "    def forward(self, x):\n",
    "        xp = cuda.get_array_module(x)\n",
    "        y = xp.cos(x)\n",
    "        return y\n",
    "    \n",
    "    def backward(self, gy):\n",
    "        x, = self.inputs\n",
    "        gx = gy * -sin(x)\n",
    "        return gx\n",
    "\n",
    "def cos(x):\n",
    "    return Cos()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh(Function):\n",
    "    def forward(self, x):\n",
    "        xp = cuda.get_array_module(x)\n",
    "        y = xp.tanh(x)\n",
    "        return y\n",
    "    \n",
    "    def backward(self, gy):\n",
    "        y = self.outputs[0]()\n",
    "        gx = gy * (1- y * y)\n",
    "        return gx\n",
    "\n",
    "def tanh(x):\n",
    "    return Tanh()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reshape(Function):\n",
    "    def __init__(self, shape):\n",
    "        self.shape = shape\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x_shape = x.shape\n",
    "        y = x.reshape(self.shape)\n",
    "        return y\n",
    "    \n",
    "    def backward(self, gy):\n",
    "        return reshape(gy, self.x_shape)\n",
    "    \n",
    "def reshape(x, shape):\n",
    "    if x.shape == shape:\n",
    "        return as_variable(x)\n",
    "    return Reshape(shape)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transpose(Function):\n",
    "    def __init__(self, axes = None):\n",
    "        self.axes = axes\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = x.transpose(self.axes)\n",
    "        return y\n",
    "    \n",
    "    def backward(self, gy):\n",
    "        if self.axes is None:\n",
    "            return transpose(gy)\n",
    "        \n",
    "        axes_len = len(self.axes)\n",
    "        inv_axes = tuple(np.argsort([ax % axes_len for ax in self.axes]))\n",
    "        return transpose(gy, inv_axes)\n",
    "    \n",
    "def transpose(x, axes=None):\n",
    "    return Transpose(axes)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sum(Function):\n",
    "    def __init__(self, axis, keepdims):\n",
    "        self.axis = axis\n",
    "        self.keepdims = keepdims\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x_shape = x.shape\n",
    "        y = x.sum(axis=self.axis, keepdims=self.keepdims)\n",
    "        return y\n",
    "    \n",
    "    def backward(self, gy):\n",
    "        gy = utils.reshape_sum_backward(gy, self.x_shape, self.axis, self.keepdims)\n",
    "        gx = broadcast_to(gy, self.x_shape)\n",
    "        return gx\n",
    "    \n",
    "def sum(x, axis=None, keepdims=False):\n",
    "    return Sum(axis, keepdims)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BroadcastTo(Function):\n",
    "    def __init__(self, shape):\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x_shape = x.shape\n",
    "        xp = dezero.cuda.get_array_module(x)\n",
    "        y = xp.broadcast_to(x, self.shape)\n",
    "        y# = np.broadcast_to(x, self.shape)\n",
    "        return y\n",
    "    \n",
    "    def backward(self, gy):\n",
    "        gx = sum_to(gy, self.x_shape)\n",
    "        return gx\n",
    "\n",
    "def broadcast_to(x, shape):\n",
    "      if x.shape == shape:\n",
    "        return as_variable(x)\n",
    "      return BroadcastTo(shape)(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dezero import utils\n",
    "\n",
    "class SumTo(Function):\n",
    "    def __init__(self, shape):\n",
    "        self.shape = shape\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x_shape = x.shape\n",
    "        y = utils.sum_to(x, self.shape)\n",
    "        return y\n",
    "    \n",
    "    def backward(self, gy):\n",
    "        gx = broadcast_to(gy, self.x_shape)\n",
    "        return gx\n",
    "\n",
    "def sum_to(x, shape):\n",
    "    if x.shape == shape:\n",
    "        return as_variable(x)\n",
    "    return SumTo(shape)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatMul(Function):\n",
    "    def forward(self, x, W):\n",
    "        y = x.dot(W)\n",
    "        return y\n",
    "    \n",
    "    def backward(self, gy):\n",
    "        x, W = self.inputs\n",
    "        gx = matmul(gy, W.T)\n",
    "        gW = matmul(x.T, gy)\n",
    "        return gx, gW\n",
    "    \n",
    "def matmul(x, W):\n",
    "    return MatMul()(x, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanSquaredError(Function):\n",
    "    def forward(self, x0, x1):\n",
    "        diff = x0 - x1\n",
    "        y = (diff ** 2).sum() / len(diff)\n",
    "        return y\n",
    "    \n",
    "    def backward(self, gy):\n",
    "        x0, x1 = self.inputs\n",
    "        diff = x0 - x1\n",
    "        gy = broadcast_to(gy, diff.shape)\n",
    "        gx0 = gy * diff * (2. / len(diff))\n",
    "        gx1 = -gx0\n",
    "        return gx0, gx1\n",
    "    \n",
    "def mean_squared_error(x0, x1):\n",
    "    return MeanSquaredError()(x0, x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Function):\n",
    "    def forward(self, x, W, b):\n",
    "        y = x.dot(W)\n",
    "        if b is not None:\n",
    "            y += b\n",
    "        return y\n",
    "\n",
    "    def backward(self, gy):\n",
    "        x, W, b = self.inputs\n",
    "        gb = None if b.data is None else sum_to(gy, b.shape)\n",
    "        gx = matmul(gy, W.T)\n",
    "        gW = matmul(x.T, gy)\n",
    "        return gx, gW, gb\n",
    "\n",
    "\n",
    "def linear(x, W, b=None):\n",
    "    return Linear()(x, W, b)\n",
    "\n",
    "\n",
    "\n",
    "def linear_simple(x ,W, b=None):\n",
    "    x, W = as_variable(x), as_variable(W)\n",
    "    t = matmul(x, W)\n",
    "    if b in None:\n",
    "        return t\n",
    "        \n",
    "    y = t + b\n",
    "    t.data = None\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid(Function):\n",
    "    def forward(self, x):\n",
    "        xp = cuda.get_array_module(x)\n",
    "        #y = 1 / (1 + xp.exp(-x))\n",
    "        y = xp.tanh(x * 0.5) * 0.5 + 0.5  # Better implementation\n",
    "        #y = tanh(x * 0.5) * 0.5 + 0.5 \n",
    "        return y\n",
    "\n",
    "    def backward(self, gy):\n",
    "        y = self.outputs[0]()\n",
    "        gx = gy * y * (1 - y)\n",
    "        return gx\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return Sigmoid()(x)\n",
    "\n",
    "\n",
    "def sigmoid_simple(x):\n",
    "    x = as_variable(x)\n",
    "    y = 1 / (1 + exp(-x))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exp(Function):\n",
    "    def forward(self, x):\n",
    "        xp = cuda.get_array_module(x)\n",
    "        y = xp.exp(x)\n",
    "        #y = np.exp(x)\n",
    "        return y\n",
    "\n",
    "    def backward(self, gy):\n",
    "        y = self.outputs[0]()  # weakref\n",
    "        gx = gy * y\n",
    "        return gx\n",
    "\n",
    "\n",
    "def exp(x):\n",
    "    return Exp()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetItem(Function):\n",
    "    def __init__(self, slices):\n",
    "        self.slices = slices\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = x[self.slices]\n",
    "        return y\n",
    "    \n",
    "    def backward(self, gy):\n",
    "        x, = self.inputs\n",
    "        f = GetItemGrad(self.slices, x.shape)\n",
    "        return f(gy)\n",
    "    \n",
    "def get_item(x, slices):\n",
    "    return GetItem(slices)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetItemGrad(Function):\n",
    "    def __init__(self, slices, in_shape):\n",
    "        self.slices = slices\n",
    "        self.in_shape = in_shape\n",
    "        \n",
    "    def forward(self, gy):\n",
    "        gx = np.zeros(self.in_shape)\n",
    "        np.add.at(gx, self.slices, gy)\n",
    "        return gx\n",
    "    \n",
    "    def backward(self, ggx):\n",
    "        return get_item(ggx, self.slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax(Function):\n",
    "    def __init__(self, axis=1):\n",
    "        self.axis = axis\n",
    "\n",
    "    def forward(self, x):\n",
    "        xp = cuda.get_array_module(x)\n",
    "        y = x - x.max(axis=self.axis, keepdims=True)\n",
    "        y = xp.exp(y)\n",
    "        y /= y.sum(axis=self.axis, keepdims=True)\n",
    "        return y\n",
    "\n",
    "    def backward(self, gy):\n",
    "        y = self.outputs[0]()\n",
    "        gx = y * gy\n",
    "        sumdx = gx.sum(axis=self.axis, keepdims=True)\n",
    "        gx -= y * sumdx\n",
    "        return gx\n",
    "\n",
    "\n",
    "def softmax(x, axis=1):\n",
    "    return Softmax(axis)(x)\n",
    "\n",
    "def softmax_simple(x, axis=1):\n",
    "    x = as_variable(x)\n",
    "    y = exp(x)\n",
    "    sum_y = sum(y, axis=axis, keepdims=True)\n",
    "    return y / sum_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxCrossEntropy(Function):\n",
    "    def forward(self, x, t):\n",
    "        N = x.shape[0]\n",
    "        log_z = utils.logsumexp(x, axis=1)\n",
    "        log_p = x - log_z\n",
    "        log_p = log_p[np.arange(N), t.ravel()]\n",
    "        y = -log_p.sum() / np.float32(N)\n",
    "        return y\n",
    "\n",
    "    def backward(self, gy):\n",
    "        x, t = self.inputs\n",
    "        N, CLS_NUM = x.shape\n",
    "\n",
    "        gy *= 1/N\n",
    "        y = softmax(x)\n",
    "        # convert to one-hot\n",
    "        xp = cuda.get_array_module(t.data)\n",
    "        t_onehot = xp.eye(CLS_NUM, dtype=t.dtype)[t.data]\n",
    "        y = (y - t_onehot) * gy\n",
    "        return y\n",
    "\n",
    "\n",
    "def softmax_cross_entropy(x, t):\n",
    "    return SoftmaxCrossEntropy()(x, t)\n",
    "\n",
    "def softmax_cross_entropy_simple(x, t):\n",
    "    x, t = as_variable(x), as_variable(t)\n",
    "    N = x.shape[0]\n",
    "    \n",
    "    p = softmax_simple(x)\n",
    "    p = clip(p, 1e-15, 1.0)\n",
    "    log_p = log(p)\n",
    "    tlog_p = log_p[np.arange(N), t.data]\n",
    "    y = -1 * sum(tlog_p) / N\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Clip(Function):\n",
    "    def __init__(self, x_min, x_max):\n",
    "        self.x_min = x_min\n",
    "        self.x_max = x_max\n",
    "\n",
    "    def forward(self, x):\n",
    "        xp = cuda.get_array_module(x)\n",
    "        y = xp.clip(x, self.x_min, self.x_max)\n",
    "        #y = np.clip(x, self.x_min, self.x_max)\n",
    "        return y\n",
    "\n",
    "    def backward(self, gy):\n",
    "        x, = self.inputs\n",
    "        mask = (x.data >= self.x_min) * (x.data <= self.x_max)\n",
    "        gx = gy * mask\n",
    "        return gx\n",
    "\n",
    "\n",
    "def clip(x, x_min, x_max):\n",
    "    return Clip(x_min, x_max)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Log(Function):\n",
    "    def forward(self, x):\n",
    "        xp = cuda.get_array_module(x)\n",
    "        y = xp.log(x)\n",
    "        #y = np.log(x)\n",
    "        return y\n",
    "\n",
    "    def backward(self, gy):\n",
    "        x, = self.inputs\n",
    "        gx = gy / x\n",
    "        return gx\n",
    "\n",
    "\n",
    "def log(x):\n",
    "    return Log()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y, t):\n",
    "    y, t = as_variable(y), as_variable(t)\n",
    "    \n",
    "    pred = y.data.argmax(axis=1).reshape(t.shape)\n",
    "    result = (pred == t.data)\n",
    "    acc = result.mean()\n",
    "    return Variable(as_array(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU(Function):\n",
    "    def forward(self, x):\n",
    "        xp = cuda.get_array_module(x)\n",
    "        y = xp.maximum(x, 0.0)\n",
    "        return y\n",
    "    \n",
    "    def backward(self, gy):\n",
    "        x, = self.inputs\n",
    "        mask = x.data > 0\n",
    "        gx = gy * mask\n",
    "        return gx\n",
    "    \n",
    "def relu(x):\n",
    "    return ReLU()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout(x, dropout_ratio=0.5):\n",
    "    x = as_variable(x)\n",
    "    \n",
    "    if dezero.Config.train:\n",
    "        xp = cuda.get_array_module(x)\n",
    "        mask = xp.random.rand(*x.shape) > dropout_ratio\n",
    "        scale = xp.array(1.0 - dropout_ratio).astype(x.dtype)\n",
    "        y = x * mask / scale\n",
    "        return y\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Max(Function):\n",
    "    def __init__(self, axis=None, keepdims=False):\n",
    "        self.axis = axis\n",
    "        self.keepdims = keepdims\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = x.max(axis=self.axis, keepdims=self.keepdims)\n",
    "        return y\n",
    "\n",
    "    def backward(self, gy):\n",
    "        x = self.inputs[0]\n",
    "        y = self.outputs[0]()  # weakref\n",
    "\n",
    "        shape = utils.max_backward_shape(x, self.axis)\n",
    "        gy = reshape(gy, shape)\n",
    "        y = reshape(y, shape)\n",
    "        cond = (x.data == y.data)\n",
    "        gy = broadcast_to(gy, cond.shape)\n",
    "        return gy * cond\n",
    "\n",
    "\n",
    "class Min(Max):\n",
    "    def forward(self, x):\n",
    "        y = x.min(axis=self.axis, keepdims=self.keepdims)\n",
    "        return y\n",
    "\n",
    "\n",
    "def max(x, axis=None, keepdims=False):\n",
    "    return Max(axis, keepdims)(x)\n",
    "\n",
    "\n",
    "def min(x, axis=None, keepdims=False):\n",
    "    return Min(axis, keepdims)(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_dezero)",
   "language": "python",
   "name": "conda_dezero"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
