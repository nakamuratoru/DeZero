{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dezero.core import Parameter\n",
    "import weakref\n",
    "import numpy as np\n",
    "import dezero.functions as F\n",
    "import os\n",
    "from dezero import cuda\n",
    "from dezero.utils import pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self._params = set()\n",
    "        \n",
    "    def __setattr__(self, name, value):\n",
    "        if isinstance(value, (Parameter, Layer)):\n",
    "            self._params.add(name)\n",
    "        super().__setattr__(name, value)\n",
    "        \n",
    "    def __call__(self, *inputs):\n",
    "        outputs = self.forward(*inputs)\n",
    "        if not isinstance(outputs, tuple):\n",
    "            outputs = (outputs,)\n",
    "        self.inputs = [weakref.ref(x) for x in inputs]\n",
    "        self.outputs = [weakref.ref(y) for y in outputs]\n",
    "        return outputs if len(outputs) > 1 else outputs[0]\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def params(self):\n",
    "        for name in self._params:\n",
    "            obj = self.__dict__[name]\n",
    "            \n",
    "            if isinstance(obj, Layer):\n",
    "                yield from obj.params()\n",
    "            else:\n",
    "                yield obj\n",
    "            \n",
    "    def cleargrads(self):\n",
    "        for param in self.params():\n",
    "            param.cleargrad()\n",
    "            \n",
    "    def to_cpu(self):\n",
    "        for param in self.params():\n",
    "            param.to_cpu()\n",
    "            \n",
    "    def to_gpu(self):\n",
    "        for param in self.params():\n",
    "            param.to_gpu()\n",
    "            \n",
    "    def _flatten_params(self, params_dict, parent_key=\"\"):\n",
    "        for name in self._params:\n",
    "            obj = self.__dict__[name]\n",
    "            key = parent_key  + \"/\" + name if parent_key else name\n",
    "            \n",
    "            if isinstance(obj, Layer):\n",
    "                obj._flatten_params(params_dict, key)\n",
    "            else:\n",
    "                params_dict[key] = obj\n",
    "                \n",
    "    def save_weights(self, path):\n",
    "        self.to_cpu()\n",
    "        \n",
    "        params_dict = {}\n",
    "        self._flatten_params(params_dict)\n",
    "        array_dict = {key: param.data for key, param in params_dict.items() if param is not None}\n",
    "        try:\n",
    "            np.savez_compressed(path, **array_dict)\n",
    "        except (Excetption, KeyboardInterrupt) as e:\n",
    "            if os.path.exists(path):\n",
    "                os.remove(path)\n",
    "            raise\n",
    "            \n",
    "    def load_weights(self, path):\n",
    "        npz = np.load(path)\n",
    "        params_dict = {}\n",
    "        self._flatten_params(params_dict)\n",
    "        for key, param in params_dict.items():\n",
    "            param.data = npz[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Layer):\n",
    "    def __init__(self, out_size, nobias=False, dtype=np.float32, in_size=None):\n",
    "        super().__init__()\n",
    "        self.in_size = in_size\n",
    "        self.out_size = out_size\n",
    "        self.dtype = dtype\n",
    "        \n",
    "        self.W = Parameter(None, name=\"W\")\n",
    "        if self.in_size is not None:\n",
    "            self._init_W()\n",
    "            \n",
    "        if nobias:\n",
    "            self.b = None\n",
    "        else:\n",
    "            self.b = Parameter(np.zeros(out_size, dtype=dtype), name=\"b\")\n",
    "            \n",
    "    def _init_W(self):\n",
    "        I, O = self.in_size, self.out_size\n",
    "        W_data = np.random.randn(I, O).astype(self.dtype) * np.sqrt(1 / I)\n",
    "        self.W.data = W_data\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.W.data is None:\n",
    "            self.in_size = x.shape[1]\n",
    "            self._init_W()\n",
    "            \n",
    "        y = F.linear(x, self.W, self.b)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d(Layer):\n",
    "    def __init__(self, out_channels, kernel_size, stride=1,\n",
    "                         pad=0, nobias=False, dtype=np.float32, in_channels=None):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        self.dtype = dtype\n",
    "        \n",
    "        self.W = Parameter(None, name=\"W\")\n",
    "        if in_channels is not None:\n",
    "            self._init_W()\n",
    "            \n",
    "        if nobias:\n",
    "            self.b = None\n",
    "        else:\n",
    "            self.b = Parameter(np.zeros(out_channels, dtype=dtype), name=\"b\")\n",
    "            \n",
    "    def _init_W(self, xp=np):\n",
    "        C, OC = self.in_channels, self.out_channels\n",
    "        KH, KW = pair(sel.kernel_size)\n",
    "        scale = np.sqrt(1 / (C * KH * KW))\n",
    "        W_data = xp.random.randn(OC, C, KH, KW).astype(self.dtype) * scale\n",
    "        self.W.data = W_data\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.W.data is None:\n",
    "            self.in_channels = x.shape[1]\n",
    "            xp = cuda.get_array_module(x)\n",
    "            self._init_W(xp)\n",
    "            \n",
    "        y = F.conv2d_simple(x, self.W, self.b, self.stride, self.pad)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(Layer):\n",
    "    def __init__(self, hidden_size, in_size=None):\n",
    "        super().__init__()\n",
    "        self.x2h = Linear(hidden_size, in_size=in_size)\n",
    "        self.h2h = Linear(hidden_size, in_size=in_size, nobias=True)\n",
    "        self.h = None\n",
    "        \n",
    "    def reset_state(self):\n",
    "        self.h = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.h is None:\n",
    "            h_new = F.tanh(self.x2h(x))\n",
    "        else:\n",
    "            h_new = F.tanh(self.x2h(x) + self.h2h(self.h))\n",
    "        self.h = h_new\n",
    "        return h_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(Layer):\n",
    "    def __init__(self, hidden_size, in_size=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        H, I = hidden_size, in_size\n",
    "        self.x2f = Linear(H, in_size=I)\n",
    "        self.x2i = Linear(H, in_size=I)\n",
    "        self.x2o = Linear(H, in_size=I)\n",
    "        self.x2u = Linear(H, in_size=I)\n",
    "        self.h2f = Linear(H, in_size=H, nobias=True)\n",
    "        self.h2i = Linear(H, in_size=H, nobias=True)\n",
    "        self.h2o = Linear(H, in_size=H, nobias=True)\n",
    "        self.h2u = Linear(H, in_size=H, nobias=True)\n",
    "        self.reset_state()\n",
    "        \n",
    "    def reset_state(self):\n",
    "        self.h = None\n",
    "        self.c = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.h is None:\n",
    "            f = F.sigmoid(self.x2f(x))\n",
    "            i = F.sigmoid(self.x2i(x))\n",
    "            o = F.sigmoid(self.x2o(x))\n",
    "            u = F.sigmoid(self.x2u(x))\n",
    "        else:\n",
    "            f = F.sigmoid(self.x2f(x) + self.h2f(self.h))\n",
    "            i = F.sigmoid(self.x2i(x) + self.h2i(self.h))\n",
    "            o = F.sigmoid(self.x2u(x) + self.h2u(self.h))\n",
    "            u = F.tanh(self.x2u(x) + self.h2u(self.h))\n",
    "            \n",
    "        if self.c is None:\n",
    "            c_new = (i * u)\n",
    "        else:\n",
    "            c_new = (f * self.c) + (i * u)\n",
    "            \n",
    "        h_new = o * F.tanh(c_new)\n",
    "        \n",
    "        self.h, self.c = h_new, c_new\n",
    "        return h_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_dezero)",
   "language": "python",
   "name": "conda_dezero"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
